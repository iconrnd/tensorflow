{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0ff1547",
   "metadata": {},
   "source": [
    "## Text generation with Char RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d6de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c46c57",
   "metadata": {},
   "source": [
    "# Loading text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f17482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespear_url = \"https://homl.info/shakespeare\"\n",
    "filepath = tf.keras.utils.get_file('shakespear.txt', shakespear_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d17771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vi0/.keras/datasets/shakespear.txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e703527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath) as f:\n",
    "    shakespear_txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8db5ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespear_txt[:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e3eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer = tf.keras.layers.TextVectorization(split='character',\n",
    "                                                  standardize='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84e077",
   "metadata": {},
   "source": [
    "# Tokenizig and encoding at character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e473f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer.adapt([shakespear_txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d8264fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " ' ',\n",
       " 'e',\n",
       " 't',\n",
       " 'o',\n",
       " 'a',\n",
       " 'i',\n",
       " 'h',\n",
       " 's',\n",
       " 'r',\n",
       " 'n',\n",
       " '\\n',\n",
       " 'l',\n",
       " 'd',\n",
       " 'u',\n",
       " 'm',\n",
       " 'y',\n",
       " 'w',\n",
       " ',',\n",
       " 'c',\n",
       " 'f',\n",
       " 'g',\n",
       " 'b',\n",
       " 'p',\n",
       " ':',\n",
       " 'k',\n",
       " 'v',\n",
       " '.',\n",
       " \"'\",\n",
       " ';',\n",
       " '?',\n",
       " '!',\n",
       " '-',\n",
       " 'j',\n",
       " 'q',\n",
       " 'x',\n",
       " 'z',\n",
       " '3',\n",
       " '&',\n",
       " '$']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd8c5469",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = text_vec_layer([shakespear_txt])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76881aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([21,  7, 10, ..., 22, 28, 12])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c339cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing code 0 and 1 reserved for padding and unknown characters \n",
    "# (codes start at 2 before that removal so now 0 and 1 will be some chars)\n",
    "encoded -= 2\n",
    "\n",
    "n_tokens = text_vec_layer.vocabulary_size() - 2\n",
    "dataset_size = len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09913f3e-44c1-48ea-a25b-edec5ce3edec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b30a1",
   "metadata": {},
   "source": [
    "# Dataset windowing with a single char shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05e4ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ede73773",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.window(5, shift=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e48ad38-988a-415c-ab77-0eb1b28f0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[ [vx, vy], [feats] ], [], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b90e23-bfa2-4356-a009-8ececd2c0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "0 [0,..., 12],\n",
    "[0,..., 12]\n",
    "...\n",
    "31 ...    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ff99f95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "tf.Tensor(19, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "\n",
      "\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "\n",
      "\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(18, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for sample in ds.take(3):\n",
    "    print('\\n')\n",
    "    for x in sample:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1f21282-05f0-46a5-b70d-7d5acafb8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.flat_map(lambda window_ds: window_ds.batch(5 + 1))\n",
    "ds = ds.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b203acf4-51ad-489c-a92f-ef65e40cf458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "tf.Tensor([19  5  8  7  2], shape=(5,), dtype=int64)\n",
      "tf.Tensor([5 8 7 2 0], shape=(5,), dtype=int64)\n",
      "\n",
      "\n",
      "tf.Tensor([ 8  7  2  0 18], shape=(5,), dtype=int64)\n",
      "tf.Tensor([ 7  2  0 18  5], shape=(5,), dtype=int64)\n",
      "\n",
      "\n",
      "tf.Tensor([ 2  0 18  5  2], shape=(5,), dtype=int64)\n",
      "tf.Tensor([ 0 18  5  2  5], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for sample in ds.take(3):\n",
    "    print('\\n')\n",
    "    for x in sample:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fd543e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length+1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=100_000, seed=seed)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])[[vx, vy]] ).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79687457",
   "metadata": {},
   "source": [
    "# Preparing train, val, test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5359c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 100\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b62eb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True, seed=42)\n",
    "valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n",
    "test_set = to_dataset(encoded[:1_060_000], length=length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27413e09-09e7-4dec-b952-233f554bb9b7",
   "metadata": {},
   "source": [
    "# This model has as many outputs as tokens, so at char level split it is relatively small. For word tokens it would probably be untractabe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "166689d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "491318c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='nadam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b9543de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chkpt = tf.keras.callbacks.ModelCheckpoint('shakespear_model',\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3166974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-24 13:05:02.270637: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-09-24 13:05:02.287390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-09-24 13:05:02.349004: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff608ea8390 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-24 13:05:02.349032: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-09-24 13:05:02.361616: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-24 13:05:02.510112: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  31246/Unknown - 133s 4ms/step - loss: 1.3938 - accuracy: 0.5737"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-24 13:07:08.980296: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 16739376533431514147\n",
      "2023-09-24 13:07:08.980324: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14144194180811173346\n",
      "2023-09-24 13:07:08.980334: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 5286058283677343576\n",
      "2023-09-24 13:07:13.303978: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 16739376533431514147\n",
      "2023-09-24 13:07:13.304003: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14144194180811173346\n",
      "2023-09-24 13:07:13.304007: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 8376685432050931232\n",
      "2023-09-24 13:07:13.304016: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 5286058283677343576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 138s 4ms/step - loss: 1.3938 - accuracy: 0.5737 - val_loss: 1.6064 - val_accuracy: 0.5331\n",
      "Epoch 2/10\n",
      "31240/31247 [============================>.] - ETA: 0s - loss: 1.2931 - accuracy: 0.5972INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 153s 5ms/step - loss: 1.2931 - accuracy: 0.5972 - val_loss: 1.5781 - val_accuracy: 0.5417\n",
      "Epoch 3/10\n",
      "31247/31247 [==============================] - 153s 5ms/step - loss: 1.2741 - accuracy: 0.6014 - val_loss: 1.5712 - val_accuracy: 0.5405\n",
      "Epoch 4/10\n",
      "31244/31247 [============================>.] - ETA: 0s - loss: 1.2640 - accuracy: 0.6035INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 154s 5ms/step - loss: 1.2640 - accuracy: 0.6035 - val_loss: 1.5605 - val_accuracy: 0.5453\n",
      "Epoch 5/10\n",
      "31243/31247 [============================>.] - ETA: 0s - loss: 1.2574 - accuracy: 0.6049INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 158s 5ms/step - loss: 1.2574 - accuracy: 0.6049 - val_loss: 1.5583 - val_accuracy: 0.5466\n",
      "Epoch 6/10\n",
      "31242/31247 [============================>.] - ETA: 0s - loss: 1.2529 - accuracy: 0.6060INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 157s 5ms/step - loss: 1.2529 - accuracy: 0.6060 - val_loss: 1.5577 - val_accuracy: 0.5495\n",
      "Epoch 7/10\n",
      "31246/31247 [============================>.] - ETA: 0s - loss: 1.2493 - accuracy: 0.6067INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 157s 5ms/step - loss: 1.2493 - accuracy: 0.6067 - val_loss: 1.5504 - val_accuracy: 0.5500\n",
      "Epoch 8/10\n",
      "31247/31247 [==============================] - 153s 5ms/step - loss: 1.2472 - accuracy: 0.6074 - val_loss: 1.5538 - val_accuracy: 0.5478\n",
      "Epoch 9/10\n",
      "31246/31247 [============================>.] - ETA: 0s - loss: 1.2450 - accuracy: 0.6078INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 154s 5ms/step - loss: 1.2450 - accuracy: 0.6078 - val_loss: 1.5519 - val_accuracy: 0.5502\n",
      "Epoch 10/10\n",
      "31247/31247 [==============================] - 154s 5ms/step - loss: 1.2434 - accuracy: 0.6083 - val_loss: 1.5428 - val_accuracy: 0.5494\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set,\n",
    "                    validation_data=valid_set,\n",
    "                    epochs=10,\n",
    "                    callbacks=model_chkpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edced342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously trained model got dataset based on encoded input\n",
    "# Here we allow for pure text ingestion during inference with encoding/tokenization done\n",
    "# within the model\n",
    "\n",
    "final_model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Lambda(lambda x: x-2),\n",
    "    model\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe10ad",
   "metadata": {},
   "source": [
    "# Direct predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e6c94d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 200ms/step\n"
     ]
    }
   ],
   "source": [
    "y_proba = final_model.predict([\"To be or not to b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cb2047c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"To be or not to b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fcf5971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 17, 39)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A batch of one sentence of length 17 returned\n",
    "# with a probability distribution over\n",
    "# 39 possible chars/tokens\n",
    "y_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85899d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.86649723e-11, 8.35158348e-01, 1.68423383e-11, 2.72461679e-02,\n",
       "       1.22674080e-02, 1.55899301e-02, 4.27650519e-08, 4.20408917e-08,\n",
       "       4.73230183e-02, 1.17821635e-07, 2.32666122e-12, 2.66743433e-02,\n",
       "       3.45763862e-10, 2.94391215e-02, 1.32026353e-05, 6.28691632e-03,\n",
       "       1.05333179e-07, 7.68806546e-11, 2.79281893e-12, 3.24001732e-08,\n",
       "       7.74614510e-15, 1.09816233e-06, 7.41741735e-09, 4.17692964e-12,\n",
       "       2.63939721e-11, 2.98858112e-08, 5.17616297e-11, 1.57950417e-08,\n",
       "       1.20890901e-11, 1.99622055e-11, 7.75813441e-12, 1.21248827e-11,\n",
       "       4.28895390e-08, 2.21203394e-12, 1.66966146e-11, 4.37479081e-11,\n",
       "       3.57669505e-18, 1.65201681e-19, 1.76836897e-21], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retured model output is the whole sequence \n",
    "# shifted to the right with a single new characted appended\n",
    "# We take it for inspection\n",
    "y_proba[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fb8d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = y_proba[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ad0ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.argmax(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33b35f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correctly predicted character\n",
    "text_vec_layer.get_vocabulary()[y_pred + 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab853a75",
   "metadata": {},
   "source": [
    "# Exploring policy around fixed RNN prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3657ab06",
   "metadata": {},
   "source": [
    "Using NN output as probablity distribution and sampling from it.\n",
    "\n",
    "Could also employ nucleus sampling where some top number of predictions is used each time for sampling whose collective probability exceeds some threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "522143c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=int64, numpy=array([[0, 0, 1, 1, 1, 0, 0, 0]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probas = tf.math.log([[0.5, 0.4, 0.1]])\n",
    "tf.random.set_seed(42)\n",
    "tf.random.categorical(log_probas, num_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86eab5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, model, temperature=1):\n",
    "    y_proba = model.predict([text])[0, -1:]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0,0]\n",
    "    return text_vec_layer.get_vocabulary()[char_id + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3761ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_text(text, n_chars, model, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, model, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c6fa52",
   "metadata": {},
   "source": [
    "* This network with dataset window size 100 can learn up to 100 characters long sequences. \n",
    "* Longer sequences require larger networks or stateful network, or more advanced architecture like transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a66a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "extend_text(\"Thee shall not fall for whom the crown weights\", 100, final_model, temperature=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d694bb8c",
   "metadata": {},
   "source": [
    "# Stateful RNN: training new batch where the previous one left off to capture longer range correlations for longer sentences generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "652332cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "312a1fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset_for_stateful_rnn(sequence, length):\n",
    "    # Injested dataset is just a one long stream of 1-char encodings\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    \n",
    "    # Creates nested dataset of window datasets of size (length + 1) with 1-char elements per window\n",
    "    ds = ds.window(length + 1, shift=length, drop_remainder=True)\n",
    "    \n",
    "    # Lambda glues together each window 1-char elements and then batch(1) batches the final dataset\n",
    "    # Here batch size is 1 specifically for the statuful network training\n",
    "    # For more general batching one has to prepare dataset specifically by e.g.\n",
    "    # splitting it into n parts and then place each part on its place withing the final ds batch\n",
    "    ds = ds.flat_map(lambda window: window.batch(length + 1)).batch(1)\n",
    "    \n",
    "    # The returned sample will have two elements, two sentences shifted by 1\n",
    "    # for training input and target\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a747e2a9-8f11-4c7f-b7c6-10baa0c9fd21",
   "metadata": {},
   "source": [
    "## Batching ds from the solutions code:\n",
    "https://github.com/ageron/handson-ml3/blob/main/16_nlp_with_rnns_and_attention.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf1d77-7754-4480-99af-9191846f3cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows one way to prepare a batched dataset for a stateful RNN\n",
    "\n",
    "def to_non_overlapping_windows(sequence, length):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift=length, drop_remainder=True)\n",
    "    return ds.flat_map(lambda window: window.batch(length + 1))\n",
    "\n",
    "def to_batched_dataset_for_stateful_rnn(sequence, length, batch_size=32):\n",
    "    parts = np.array_split(sequence, batch_size)\n",
    "    datasets = tuple(to_non_overlapping_windows(part, length) for part in parts)\n",
    "    ds = tf.data.Dataset.zip(datasets).map(lambda *windows: tf.stack(windows))\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n",
    "\n",
    "#list(to_batched_dataset_for_stateful_rnn(tf.range(20), length=3, batch_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed579bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = to_dataset_for_stateful_rnn(encoded[:1_000_000], length=length)\n",
    "valid_set = to_dataset_for_stateful_rnn(encoded[1_000_000:1_060_000], length=length)\n",
    "test_set = to_dataset_for_stateful_rnn(encoded[:1_060_000], length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16834b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1, 100), dtype=int64, numpy=\n",
      "array([[19,  5,  8,  7,  2,  0, 18,  5,  2,  5, 35,  1,  9, 23, 10, 21,\n",
      "         1, 19,  3,  8,  1,  0, 16,  1,  0, 22,  8,  3, 18,  1,  1, 12,\n",
      "         0,  4,  9, 15,  0, 19, 13,  8,  2,  6,  1,  8, 17,  0,  6,  1,\n",
      "         4,  8,  0, 14,  1,  0,  7, 22,  1,  4, 24, 26, 10, 10,  4, 11,\n",
      "        11, 23, 10,  7, 22,  1,  4, 24, 17,  0,  7, 22,  1,  4, 24, 26,\n",
      "        10, 10, 19,  5,  8,  7,  2,  0, 18,  5,  2,  5, 35,  1,  9, 23,\n",
      "        10, 15,  3, 13]])>, <tf.Tensor: shape=(1, 100), dtype=int64, numpy=\n",
      "array([[ 5,  8,  7,  2,  0, 18,  5,  2,  5, 35,  1,  9, 23, 10, 21,  1,\n",
      "        19,  3,  8,  1,  0, 16,  1,  0, 22,  8,  3, 18,  1,  1, 12,  0,\n",
      "         4,  9, 15,  0, 19, 13,  8,  2,  6,  1,  8, 17,  0,  6,  1,  4,\n",
      "         8,  0, 14,  1,  0,  7, 22,  1,  4, 24, 26, 10, 10,  4, 11, 11,\n",
      "        23, 10,  7, 22,  1,  4, 24, 17,  0,  7, 22,  1,  4, 24, 26, 10,\n",
      "        10, 19,  5,  8,  7,  2,  0, 18,  5,  2,  5, 35,  1,  9, 23, 10,\n",
      "        15,  3, 13,  0]])>)\n"
     ]
    }
   ],
   "source": [
    "for item in train_set.take(1):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8010fe",
   "metadata": {},
   "source": [
    "# Stateful RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c6758dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16, batch_input_shape=[1, None]), # was 1, None\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f07c9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()\n",
    "        \n",
    "model_chkpt = tf.keras.callbacks.ModelCheckpoint('shakespear_model',\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 save_best_only=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d611064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='nadam',\n",
    "             metrics=['accuracy'],\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ac559dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9991/Unknown - 47s 5ms/step - loss: 1.8610 - accuracy: 0.4519"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 13:00:49.892412: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 12468002509017132553\n",
      "2023-09-27 13:00:49.892444: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 13980077015368050233\n",
      "2023-09-27 13:00:49.892461: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 447728031393915026\n",
      "2023-09-27 13:00:51.457197: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 13980077015368050233\n",
      "2023-09-27 13:00:51.457224: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 12468002509017132553\n",
      "2023-09-27 13:00:51.457230: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 447728031393915026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shakespear_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "9999/9999 [==============================] - 50s 5ms/step - loss: 1.8607 - accuracy: 0.4520 - val_loss: 1.7085 - val_accuracy: 0.4889\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set,\n",
    "                   validation_data=valid_set,\n",
    "                   epochs=1,\n",
    "                   callbacks=[ResetStatesCallback(), model_chkpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0dd01e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "566a4340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 204ms/step\n",
      "[[[3.89042281e-04 1.95684806e-02 3.70772332e-02 ... 2.49786041e-04\n",
      "   3.86669650e-04 4.52092820e-04]\n",
      "  [4.05543186e-02 2.30744928e-01 1.28481418e-01 ... 2.79863912e-06\n",
      "   6.00172007e-06 3.82376857e-06]\n",
      "  [4.47216371e-06 5.04652737e-03 3.95580716e-02 ... 1.09606644e-05\n",
      "   8.55144390e-06 3.68872770e-06]\n",
      "  ...\n",
      "  [1.60388066e-04 3.45875919e-01 7.19036092e-04 ... 4.40044126e-08\n",
      "   2.42503777e-08 4.61003928e-08]\n",
      "  [7.14462459e-01 5.58487810e-02 2.06820760e-03 ... 1.26294051e-08\n",
      "   2.93860825e-09 1.01698355e-07]\n",
      "  [4.96623979e-05 2.45402101e-02 3.96034606e-02 ... 6.80763321e-07\n",
      "   3.02264681e-07 3.66973268e-07]]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[[1.4775415e-07 4.4651251e-02 1.6833520e-03 ... 2.9837672e-06\n",
      "   4.7187473e-06 2.7973711e-06]\n",
      "  [2.6613630e-05 8.9043610e-02 5.1904931e-03 ... 2.3154482e-06\n",
      "   1.6898730e-06 1.1341128e-06]\n",
      "  [4.0087188e-03 1.2978478e-02 3.8150107e-03 ... 6.7156662e-07\n",
      "   4.2688313e-07 2.1731264e-06]\n",
      "  ...\n",
      "  [1.0243160e-05 3.8950261e-01 3.2701364e-04 ... 2.7503686e-09\n",
      "   4.9824593e-09 7.8358592e-10]\n",
      "  [2.6386464e-01 3.5134789e-03 2.2305509e-03 ... 1.5481737e-07\n",
      "   1.4026685e-07 2.2175678e-07]\n",
      "  [9.9520450e-03 1.4030772e-04 1.3768291e-02 ... 2.5306392e-07\n",
      "   2.0343974e-07 2.2055750e-07]]]\n"
     ]
    }
   ],
   "source": [
    "for sample in valid_set.take(2):\n",
    "    print(model.predict(sample[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68bafaa-a791-478d-a16a-0cc03624b8c4",
   "metadata": {},
   "source": [
    "## Lifting the need for same sized batches as during training by creating stateless model and transferring trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0cc2fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prod = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "340b17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prod.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b927148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously trained model got dataset based on encoded input\n",
    "# Here we allow for pure text ingestion during inference with encoding/tokenization done\n",
    "# within the model\n",
    "final_model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Lambda(lambda x: x-2),\n",
    "    model_prod\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc2a1042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.extend_text(text, n_chars, model, temperature=1)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extend_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d8c76737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'king to so.\\nwh'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extend_text(\"king\", 10, final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136002a2",
   "metadata": {},
   "source": [
    "# Char-RNN learns higher level abstract notions like the sentiment of the text - OpenAI discovered a sentiment neuron in a char-rnn even without explicit sentiment labels. This was an early hint at unsupervised pretraining potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb18ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf39",
   "language": "python",
   "name": "tf39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
