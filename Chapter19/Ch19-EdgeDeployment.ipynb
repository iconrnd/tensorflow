{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e1d4d2-bc72-4a19-a24f-11ed722d9d40",
   "metadata": {},
   "source": [
    "## Deployment to the Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e1bd7-0eb3-4db5-a308-5afa96af6c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd5d2e1-d3f6-4ccf-9fa2-afdab5955630",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"my_mnist_model/0001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48d0826c-76a0-4c60-9151-e6cf87328526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\tfingerprint.pb\tkeras_metadata.pb  saved_model.pb  variables\n"
     ]
    }
   ],
   "source": [
    "!ls {model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2551d5-4446-4c20-9588-370332df4525",
   "metadata": {},
   "source": [
    "## TFLite converts SavedModel to an optimized cross-platform format FlatBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e260bd9-f7b4-497a-ab28-2000b46ba2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "054d14cb-7e74-4578-bece-ecc6ab786d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 16:08:56.464424: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-02-16 16:08:56.464444: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-02-16 16:08:56.464849: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: my_mnist_model/0001\n",
      "2024-02-16 16:08:56.465517: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-02-16 16:08:56.465527: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: my_mnist_model/0001\n",
      "2024-02-16 16:08:56.467668: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-02-16 16:08:56.468158: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-02-16 16:08:56.493614: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: my_mnist_model/0001\n",
      "2024-02-16 16:08:56.499370: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 34523 microseconds.\n",
      "2024-02-16 16:08:56.511319: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 7, Total Ops 15, % non-converted = 46.67 %\n",
      " * 7 ARITH ops\n",
      "\n",
      "- arith.constant:    7 occurrences  (f32: 6, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e249f-1bc9-48bf-9112-f29599b524e9",
   "metadata": {},
   "source": [
    "## Storing converted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c6374ce-dcfd-4f6a-84cd-bb213a102ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"my_converted_savedmodel.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528183d1-d3bf-40f2-b2a7-eb30fa0dd4a9",
   "metadata": {},
   "source": [
    "### One can also direcltly convert model to FlatBuffer:\n",
    "* tf.lite.TFLiteConverter.from_keras_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fde43b-091b-41a8-9f8d-bfe3103ed9e3",
   "metadata": {},
   "source": [
    "### Tool for graphs visualisation:\n",
    "\n",
    "* https://netron.app/\n",
    "\n",
    "### TFLite pretraine dmodels\n",
    "\n",
    "* https://www.tensorflow.org/lite/models\n",
    "\n",
    "### Low level graph transforming tool:\n",
    "\n",
    "* https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd73e82-135b-4bea-8c2b-c9d2e6eb7b75",
   "metadata": {},
   "source": [
    "## Post-training quantization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a25b6-7ff2-44d1-a5df-618d8c3c7f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f884654-2b37-4b78-ac04-b39e52769532",
   "metadata": {},
   "source": [
    "### Quantization can be applied also to actvations which allows for full integer based inference\n",
    "### This may require quantization-aware training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5f4481-6695-4738-8919-059af9c0e346",
   "metadata": {},
   "source": [
    "## Web browser deployment with TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f5e291-0585-47b9-8e0d-f958457777aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import \"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest\";\n",
    "import \"https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@1.0.0\";\n",
    "const image = document.getElementById(\"image\");\n",
    "mobilenet.load().then(model => {\n",
    "model.classify(image).then(predictions => {\n",
    "for (var i = 0; i < predictions.length; i++) {\n",
    "let className = predictions[i].className\n",
    "let proba = (predictions[i].probability * 100).toFixed(1)\n",
    "console.log(className + \" : \" + proba + \"%\");\n",
    "}\n",
    "});\n",
    "});"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf39",
   "language": "python",
   "name": "tf39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
